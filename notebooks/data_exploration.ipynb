{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hailey\\f1-time-series-blockchain-predictor\\src\\utils\\data_helpers.py:156: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n",
      "c:\\Users\\hailey\\f1-time-series-blockchain-predictor\\src\\utils\\data_helpers.py:156: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n",
      "c:\\Users\\hailey\\f1-time-series-blockchain-predictor\\src\\utils\\data_helpers.py:156: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n",
      "c:\\Users\\hailey\\f1-time-series-blockchain-predictor\\src\\utils\\data_helpers.py:156: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n",
      "c:\\Users\\hailey\\f1-time-series-blockchain-predictor\\src\\utils\\data_helpers.py:156: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets have been cleaned and saved to the processed folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from src.utils.data_helpers import (\n",
    "    clean_circuits,\n",
    "    clean_constructor_results,\n",
    "    clean_constructor_standings,\n",
    "    clean_constructors,\n",
    "    clean_driver_standings,\n",
    "    clean_drivers,\n",
    "    clean_lap_times,\n",
    "    clean_pit_stops,\n",
    "    clean_qualifying,\n",
    "    clean_races,\n",
    "    clean_results,\n",
    "    clean_seasons,\n",
    "    clean_sprint_results,\n",
    "    clean_status\n",
    ")\n",
    "\n",
    "# Ensure the processed data directory exists\n",
    "processed_folder = '../data/processed'\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# 1. Clean circuits.csv (example already provided)\n",
    "circuits = pd.read_csv('../data/raw/f1_world_championship/circuits.csv')\n",
    "circuits_clean = clean_circuits(circuits)\n",
    "circuits_clean.to_csv(f'{processed_folder}/circuits_clean.csv', index=False)\n",
    "\n",
    "# 2. Clean constructor_results.csv\n",
    "constructor_results = pd.read_csv('../data/raw/f1_world_championship/constructor_results.csv')\n",
    "constructor_results_clean = clean_constructor_results(constructor_results)\n",
    "constructor_results_clean.to_csv(f'{processed_folder}/constructor_results_clean.csv', index=False)\n",
    "\n",
    "# 3. Clean constructor_standings.csv\n",
    "constructor_standings = pd.read_csv('../data/raw/f1_world_championship/constructor_standings.csv')\n",
    "constructor_standings_clean = clean_constructor_standings(constructor_standings)\n",
    "constructor_standings_clean.to_csv(f'{processed_folder}/constructor_standings_clean.csv', index=False)\n",
    "\n",
    "# 4. Clean constructors.csv\n",
    "constructors = pd.read_csv('../data/raw/f1_world_championship/constructors.csv')\n",
    "constructors_clean = clean_constructors(constructors)\n",
    "constructors_clean.to_csv(f'{processed_folder}/constructors_clean.csv', index=False)\n",
    "\n",
    "# 5. Clean driver_standings.csv\n",
    "driver_standings = pd.read_csv('../data/raw/f1_world_championship/driver_standings.csv')\n",
    "driver_standings_clean = clean_driver_standings(driver_standings)\n",
    "driver_standings_clean.to_csv(f'{processed_folder}/driver_standings_clean.csv', index=False)\n",
    "\n",
    "# 6. Clean drivers.csv\n",
    "drivers = pd.read_csv('../data/raw/f1_world_championship/drivers.csv')\n",
    "drivers_clean = clean_drivers(drivers)\n",
    "drivers_clean.to_csv(f'{processed_folder}/drivers_clean.csv', index=False)\n",
    "\n",
    "# 7. Clean lap_times.csv\n",
    "lap_times = pd.read_csv('../data/raw/f1_world_championship/lap_times.csv')\n",
    "lap_times_clean = clean_lap_times(lap_times)\n",
    "lap_times_clean.to_csv(f'{processed_folder}/lap_times_clean.csv', index=False)\n",
    "\n",
    "# 8. Clean pit_stops.csv\n",
    "pit_stops = pd.read_csv('../data/raw/f1_world_championship/pit_stops.csv')\n",
    "pit_stops_clean = clean_pit_stops(pit_stops)\n",
    "pit_stops_clean.to_csv(f'{processed_folder}/pit_stops_clean.csv', index=False)\n",
    "\n",
    "# 9. Clean qualifying.csv\n",
    "qualifying = pd.read_csv('../data/raw/f1_world_championship/qualifying.csv')\n",
    "qualifying_clean = clean_qualifying(qualifying)\n",
    "qualifying_clean.to_csv(f'{processed_folder}/qualifying_clean.csv', index=False)\n",
    "\n",
    "# 10. Clean races.csv\n",
    "races = pd.read_csv('../data/raw/f1_world_championship/races.csv')\n",
    "races_clean = clean_races(races)\n",
    "races_clean.to_csv(f'{processed_folder}/races_clean.csv', index=False)\n",
    "\n",
    "# 11. Clean results.csv\n",
    "results = pd.read_csv('../data/raw/f1_world_championship/results.csv')\n",
    "results_clean = clean_results(results)\n",
    "results_clean.to_csv(f'{processed_folder}/results_clean.csv', index=False)\n",
    "\n",
    "# 12. Clean seasons.csv\n",
    "seasons = pd.read_csv('../data/raw/f1_world_championship/seasons.csv')\n",
    "seasons_clean = clean_seasons(seasons)\n",
    "seasons_clean.to_csv(f'{processed_folder}/seasons_clean.csv', index=False)\n",
    "\n",
    "# 13. Clean sprint_results.csv\n",
    "sprint_results = pd.read_csv('../data/raw/f1_world_championship/sprint_results.csv')\n",
    "sprint_results_clean = clean_sprint_results(sprint_results)\n",
    "sprint_results_clean.to_csv(f'{processed_folder}/sprint_results_clean.csv', index=False)\n",
    "\n",
    "# 14. Clean status.csv\n",
    "status = pd.read_csv('../data/raw/f1_world_championship/status.csv')\n",
    "status_clean = clean_status(status)\n",
    "status_clean.to_csv(f'{processed_folder}/status_clean.csv', index=False)\n",
    "\n",
    "print(\"All datasets have been cleaned and saved to the processed folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (26759, 61)\n",
      "   result_id  race_id  driver_id  constructor_id  number  grid  position  \\\n",
      "0          1       18          1               1    22.0     1       1.0   \n",
      "1          2       18          2               2     3.0     5       2.0   \n",
      "2          3       18          3               3     7.0     7       3.0   \n",
      "3          4       18          4               4     5.0    11       4.0   \n",
      "4          5       18          5               1    23.0     3       5.0   \n",
      "\n",
      "  position_text  position_order  points  ...  driver_standing_points  \\\n",
      "0             1               1    10.0  ...                    10.0   \n",
      "1             2               2     8.0  ...                     8.0   \n",
      "2             3               3     6.0  ...                     6.0   \n",
      "3             4               4     5.0  ...                     5.0   \n",
      "4             5               5     4.0  ...                     4.0   \n",
      "\n",
      "  driver_standing_position  constructor_result_points  \\\n",
      "0                      1.0                       14.0   \n",
      "1                      2.0                        8.0   \n",
      "2                      3.0                        9.0   \n",
      "3                      4.0                        5.0   \n",
      "4                      5.0                       14.0   \n",
      "\n",
      "  constructor_standing_position  constructor_standing_wins  \\\n",
      "0                           1.0                        1.0   \n",
      "1                           3.0                        0.0   \n",
      "2                           2.0                        0.0   \n",
      "3                           4.0                        0.0   \n",
      "4                           1.0                        1.0   \n",
      "\n",
      "                                               url_y    avg_lap_ms  num_laps  \\\n",
      "0  http://en.wikipedia.org/wiki/2008_Formula_One_...  98114.068966      58.0   \n",
      "1  http://en.wikipedia.org/wiki/2008_Formula_One_...  98208.517241      58.0   \n",
      "2  http://en.wikipedia.org/wiki/2008_Formula_One_...  98254.810345      58.0   \n",
      "3  http://en.wikipedia.org/wiki/2008_Formula_One_...  98410.293103      58.0   \n",
      "4  http://en.wikipedia.org/wiki/2008_Formula_One_...  98424.655172      58.0   \n",
      "\n",
      "   total_pit_duration  num_pit_stops  \n",
      "0                 NaN            NaN  \n",
      "1                 NaN            NaN  \n",
      "2                 NaN            NaN  \n",
      "3                 NaN            NaN  \n",
      "4                 NaN            NaN  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the folder where the cleaned files are stored\n",
    "processed_folder = '../data/processed'\n",
    "\n",
    "# Load all cleaned datasets\n",
    "circuits            = pd.read_csv(f'{processed_folder}/circuits_clean.csv')\n",
    "constructor_results = pd.read_csv(f'{processed_folder}/constructor_results_clean.csv')\n",
    "constructor_standings = pd.read_csv(f'{processed_folder}/constructor_standings_clean.csv')\n",
    "constructors        = pd.read_csv(f'{processed_folder}/constructors_clean.csv')\n",
    "driver_standings    = pd.read_csv(f'{processed_folder}/driver_standings_clean.csv')\n",
    "drivers             = pd.read_csv(f'{processed_folder}/drivers_clean.csv')\n",
    "lap_times           = pd.read_csv(f'{processed_folder}/lap_times_clean.csv')\n",
    "pit_stops           = pd.read_csv(f'{processed_folder}/pit_stops_clean.csv')\n",
    "qualifying          = pd.read_csv(f'{processed_folder}/qualifying_clean.csv')\n",
    "races               = pd.read_csv(f'{processed_folder}/races_clean.csv')\n",
    "results             = pd.read_csv(f'{processed_folder}/results_clean.csv')\n",
    "seasons             = pd.read_csv(f'{processed_folder}/seasons_clean.csv')\n",
    "sprint_results      = pd.read_csv(f'{processed_folder}/sprint_results_clean.csv')\n",
    "status              = pd.read_csv(f'{processed_folder}/status_clean.csv')\n",
    "\n",
    "# Start building the master DataFrame with results (each row represents a driver in a race)\n",
    "master_df = results.copy()\n",
    "\n",
    "# Merge race details (on race_id)\n",
    "master_df = pd.merge(master_df, races, on='race_id', how='left', suffixes=('', '_race'))\n",
    "\n",
    "# Merge circuit details using circuit_id from races\n",
    "# (Assuming races already has a column 'circuit_id')\n",
    "master_df = pd.merge(master_df, circuits[['circuit_id', 'name']], on='circuit_id', how='left', suffixes=('', '_circuit'))\n",
    "\n",
    "# Merge driver details (on driver_id)\n",
    "master_df = pd.merge(master_df, drivers, on='driver_id', how='left', suffixes=('', '_driver'))\n",
    "\n",
    "# Merge constructor details (on constructor_id)\n",
    "master_df = pd.merge(master_df, constructors, on='constructor_id', how='left', suffixes=('', '_constructor'))\n",
    "\n",
    "# Merge status (on status_id)\n",
    "master_df = pd.merge(master_df, status, on='status_id', how='left', suffixes=('', '_status'))\n",
    "\n",
    "# Merge qualifying data (using race_id and driver_id)\n",
    "# Here, we take only the qualifying position as an example.\n",
    "qualifying_subset = qualifying[['race_id', 'driver_id', 'position']].rename(columns={'position': 'qualifying_position'})\n",
    "master_df = pd.merge(master_df, qualifying_subset, on=['race_id', 'driver_id'], how='left')\n",
    "\n",
    "# Merge sprint results (using race_id and driver_id) as an extra feature.\n",
    "sprint_subset = sprint_results[['race_id', 'driver_id', 'position']].rename(columns={'position': 'sprint_position'})\n",
    "master_df = pd.merge(master_df, sprint_subset, on=['race_id', 'driver_id'], how='left')\n",
    "\n",
    "# Merge driver standings (using race_id and driver_id)\n",
    "driver_standings_subset = driver_standings[['race_id', 'driver_id', 'points', 'position']].rename(\n",
    "    columns={'points': 'driver_standing_points', 'position': 'driver_standing_position'})\n",
    "master_df = pd.merge(master_df, driver_standings_subset, on=['race_id', 'driver_id'], how='left')\n",
    "\n",
    "# Merge constructor results (using race_id and constructor_id)\n",
    "constructor_results_subset = constructor_results[['race_id', 'constructor_id', 'points']].rename(\n",
    "    columns={'points': 'constructor_result_points'})\n",
    "master_df = pd.merge(master_df, constructor_results_subset, on=['race_id', 'constructor_id'], how='left')\n",
    "\n",
    "# Merge constructor standings (using race_id and constructor_id)\n",
    "constructor_standings_subset = constructor_standings[['race_id', 'constructor_id', 'position', 'wins']].rename(\n",
    "    columns={'position': 'constructor_standing_position', 'wins': 'constructor_standing_wins'})\n",
    "master_df = pd.merge(master_df, constructor_standings_subset, on=['race_id', 'constructor_id'], how='left')\n",
    "\n",
    "# Merge seasons (using year from races)\n",
    "master_df = pd.merge(master_df, seasons, on='year', how='left')\n",
    "\n",
    "# For lap_times: aggregate average lap time and count of laps per race and driver.\n",
    "agg_lap = lap_times.groupby(['race_id', 'driver_id']).agg({\n",
    "    'milliseconds': 'mean',\n",
    "    'lap': 'count'\n",
    "}).reset_index().rename(columns={'milliseconds': 'avg_lap_ms', 'lap': 'num_laps'})\n",
    "master_df = pd.merge(master_df, agg_lap, on=['race_id', 'driver_id'], how='left')\n",
    "\n",
    "# For pit_stops: aggregate total pit duration and count of pit stops per race and driver.\n",
    "agg_pit = pit_stops.groupby(['race_id', 'driver_id']).agg({\n",
    "    'duration': 'sum',\n",
    "    'stop': 'count'\n",
    "}).reset_index().rename(columns={'duration': 'total_pit_duration', 'stop': 'num_pit_stops'})\n",
    "master_df = pd.merge(master_df, agg_pit, on=['race_id', 'driver_id'], how='left')\n",
    "\n",
    "# At this point, master_df contains merged data from all 14 datasets.\n",
    "print(\"Merged dataset shape:\", master_df.shape)\n",
    "print(master_df.head())\n",
    "\n",
    "# Save the master DataFrame to a CSV file for further analysis\n",
    "master_df.to_csv(f'{processed_folder}/merged_f1_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpython\u001b[49m \u001b[38;5;241m/\u001b[39msrc\u001b[38;5;241m/\u001b[39mml\u001b[38;5;241m/\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mpy\n",
      "\u001b[1;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
